{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e712ae74",
   "metadata": {},
   "source": [
    "# 1. Carga y Uni√≥n de Datos (Data Wrangling)\n",
    "\n",
    "## Objetivo\n",
    "Construir un solo dataset limpio y coherente con los nacimientos de Guatemala del per√≠odo 2009‚Äì2022.\n",
    "\n",
    "## Fuente de datos\n",
    "- **Origen:** Instituto Nacional de Estad√≠stica (INE) de Guatemala\n",
    "- **Formato:** Archivos SPSS (.sav)\n",
    "- **Per√≠odo:** 2009 a 2022 (14 a√±os)\n",
    "- **Unidad de an√°lisis:** Cada registro individual de nacimiento\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ca25a",
   "metadata": {},
   "source": [
    "## 1.1 Importaci√≥n de librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f81c2dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librer√≠as cargadas correctamente\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "print(\"Librer√≠as cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a44e1",
   "metadata": {},
   "source": [
    "## 1.2 Definici√≥n de rutas y archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e305031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta de datos: C:\\Users\\aeh55\\Documents\\Angel Esteban\\Universidad\\Semestre 7\\Miner√≠adeDatos\\PRY1-MD\\data\n",
      "\n",
      "Archivos .sav encontrados: 14\n",
      "----------------------------------------\n",
      "  ‚Ä¢ N2009.sav\n",
      "  ‚Ä¢ N2010.sav\n",
      "  ‚Ä¢ N2011.sav\n",
      "  ‚Ä¢ N2012.sav\n",
      "  ‚Ä¢ N2013.sav\n",
      "  ‚Ä¢ N2014.sav\n",
      "  ‚Ä¢ N2015.sav\n",
      "  ‚Ä¢ N2016.sav\n",
      "  ‚Ä¢ N2017.sav\n",
      "  ‚Ä¢ N2018.sav\n",
      "  ‚Ä¢ N2019.sav\n",
      "  ‚Ä¢ N2020.sav\n",
      "  ‚Ä¢ N2021.sav\n",
      "  ‚Ä¢ N2022.sav\n"
     ]
    }
   ],
   "source": [
    "# Ruta a la carpeta de datos\n",
    "DATA_PATH = Path('../data')\n",
    "\n",
    "# Listar archivos .sav disponibles\n",
    "archivos_sav = sorted([f for f in os.listdir(DATA_PATH) if f.endswith('.sav')])\n",
    "\n",
    "print(f\"Carpeta de datos: {DATA_PATH.resolve()}\")\n",
    "print(f\"\\nArchivos .sav encontrados: {len(archivos_sav)}\")\n",
    "print(\"-\" * 40)\n",
    "for archivo in archivos_sav:\n",
    "    print(f\"  ‚Ä¢ {archivo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e504b",
   "metadata": {},
   "source": [
    "## 1.3 Carga individual de archivos y verificaci√≥n de estructura\n",
    "\n",
    "Cargamos cada archivo y extraemos informaci√≥n sobre:\n",
    "- N√∫mero de registros\n",
    "- Variables (columnas)\n",
    "- A√±o de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269df385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando archivos...\n",
      "\n",
      "Archivo            Registros    Variables    A√±o datos\n",
      "=======================================================\n",
      "N2009.sav            351,628           37         2009 ‚úì\n",
      "N2010.sav            361,906           39         2010 ‚úì\n",
      "N2011.sav            373,692           39         2011 ‚úì\n",
      "N2012.sav            388,613           41         2012 ‚úì\n",
      "N2013.sav            387,342           41         2013 ‚úì\n",
      "N2014.sav            386,195           39         2014 ‚úì\n",
      "N2015.sav            391,425           42         2015 ‚úì\n",
      "N2016.sav            390,382           42         2016 ‚úì\n",
      "N2017.sav            381,664           42         2017 ‚úì\n",
      "N2018.sav            383,263           42         2018 ‚úì\n",
      "N2019.sav            366,855           42         2019 ‚úì\n",
      "N2020.sav            341,212           42         2020 ‚úì\n",
      "N2021.sav            345,149           42         2021 ‚úì\n",
      "N2022.sav            345,869           42         2022 ‚úì\n",
      "=======================================================\n",
      "\n",
      "Total de archivos cargados: 14\n"
     ]
    }
   ],
   "source": [
    "# Diccionario para almacenar informaci√≥n de cada archivo\n",
    "info_archivos = {}\n",
    "dataframes = {}\n",
    "metadatos = {}\n",
    "\n",
    "print(\"Cargando archivos...\\n\")\n",
    "print(f\"{'Archivo':<15} {'Registros':>12} {'Variables':>12} {'A√±o datos':>12}\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "for archivo in archivos_sav:\n",
    "    filepath = DATA_PATH / archivo\n",
    "    \n",
    "    # Cargar archivo\n",
    "    df, meta = pyreadstat.read_sav(str(filepath))\n",
    "    \n",
    "    # Extraer a√±o esperado del nombre\n",
    "    a√±o_nombre = int(archivo.replace('N', '').replace('.sav', ''))\n",
    "    \n",
    "    # Determinar a√±o real de los datos\n",
    "    if 'A√±oocu' in df.columns:\n",
    "        a√±o_datos = int(df['A√±oocu'].dropna().mode().iloc[0])\n",
    "        if a√±o_datos < 100:\n",
    "            a√±o_datos = 2000 + a√±o_datos\n",
    "    elif 'A√±oreg' in df.columns:\n",
    "        a√±o_datos = int(df['A√±oreg'].dropna().mode().iloc[0])\n",
    "    else:\n",
    "        a√±o_datos = a√±o_nombre\n",
    "    \n",
    "    # Guardar informaci√≥n\n",
    "    info_archivos[a√±o_nombre] = {\n",
    "        'archivo': archivo,\n",
    "        'registros': len(df),\n",
    "        'variables': len(df.columns),\n",
    "        'columnas': list(df.columns),\n",
    "        'a√±o_datos': a√±o_datos\n",
    "    }\n",
    "    \n",
    "    dataframes[a√±o_nombre] = df\n",
    "    metadatos[a√±o_nombre] = meta\n",
    "    \n",
    "    # Mostrar informaci√≥n\n",
    "    estado = \"‚úì\" if a√±o_nombre == a√±o_datos else \"‚ö†\"\n",
    "    print(f\"{archivo:<15} {len(df):>12,} {len(df.columns):>12} {a√±o_datos:>12} {estado}\")\n",
    "\n",
    "print(\"=\" * 55)\n",
    "print(f\"\\nTotal de archivos cargados: {len(dataframes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b0784",
   "metadata": {},
   "source": [
    "## 1.4 An√°lisis de variables por archivo\n",
    "\n",
    "Verificamos si todos los archivos tienen las mismas variables con los mismos nombres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82bacfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de variables √∫nicas encontradas: 61\n",
      "\n",
      "================================================================================\n",
      "MATRIZ DE PRESENCIA DE VARIABLES POR A√ëO\n",
      "================================================================================\n",
      "         2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022\n",
      "Areag       ‚úì    ‚úì    ‚úì    -    -    -    -    -    -    -    -    -    -    -\n",
      "Asisrec     ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "A√±oocu      ‚úì    ‚úì    ‚úì    -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "A√±oreg      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Ciuomad     -    -    -    -    ‚úì    -    -    -    -    -    -    -    -    -\n",
      "Ciuopad     -    -    -    -    ‚úì    -    -    -    -    -    -    -    -    -\n",
      "Depnam      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Depnap      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Depocu      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Depreg      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Deprem      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Deprep      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Diaocu      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Edadm       ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Edadp       ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Escivm      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Escivp      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Escolam     -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Escolap     -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Gretnm      ‚úì    -    -    -    -    -    -    -    -    -    -    -    -    -\n",
      "Gretnp      ‚úì    ‚úì    ‚úì    ‚úì    -    -    -    -    -    -    -    -    -    -\n",
      "Libras      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Mesocu      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Mesreg      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Munpnap     -    -    -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    -    -\n",
      "Mupnam      ‚úì    -    ‚úì    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Mupnap      ‚úì    -    ‚úì    ‚úì    ‚úì    -    -    -    -    -    -    -    ‚úì    ‚úì\n",
      "Mupocu      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Mupreg      -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Muprem      ‚úì    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Muprep      -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Naciom      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    -    -    -    -    -    -    -    -    -\n",
      "Naciop      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    -    -    -    -    -    -    -    -    -\n",
      "Ocupam      ‚úì    ‚úì    ‚úì    ‚úì    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Ocupap      ‚úì    ‚úì    ‚úì    ‚úì    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Onzas       ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Paisnacm    -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Paisnacp    -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Paisrem     -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Paisrep     -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "PuebloPM    -    -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    -\n",
      "PuebloPP    -    -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    -\n",
      "Pueblopm    -    -    -    -    -    -    -    -    -    -    -    -    -    ‚úì\n",
      "Pueblopp    -    -    -    -    -    -    -    -    -    -    -    -    -    ‚úì\n",
      "Sexo        ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Sitioocu    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Tipar       ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "TipoIns     -    -    -    -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Tohinm      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Tohite      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "Tohivi      ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì\n",
      "ViaPar      -    -    -    -    -    -    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    ‚úì    -\n",
      "Viapar      -    -    -    -    -    -    -    -    -    -    -    -    -    ‚úì\n",
      "ciuomad     -    -    -    -    -    ‚úì    -    -    -    -    -    -    -    -\n",
      "grupetma    -    ‚úì    ‚úì    ‚úì    -    -    -    -    -    -    -    -    -    -\n",
      "munnam      -    -    -    ‚úì    -    -    -    -    -    -    -    -    -    -\n",
      "mupnam      -    ‚úì    -    -    -    -    -    -    -    -    -    -    -    -\n",
      "mupnap      -    ‚úì    -    -    -    -    -    -    -    -    -    -    -    -\n",
      "mupreg      ‚úì    ‚úì    -    -    -    -    -    -    -    -    -    -    -    -\n",
      "muprem      -    ‚úì    -    -    -    -    -    -    -    -    -    -    -    -\n",
      "muprep      ‚úì    ‚úì    -    -    -    -    -    -    -    -    -    -    -    -\n"
     ]
    }
   ],
   "source": [
    "# Obtener todas las variables √∫nicas\n",
    "todas_variables = set()\n",
    "for a√±o, info in info_archivos.items():\n",
    "    todas_variables.update(info['columnas'])\n",
    "\n",
    "print(f\"Total de variables √∫nicas encontradas: {len(todas_variables)}\")\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MATRIZ DE PRESENCIA DE VARIABLES POR A√ëO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Crear matriz de presencia\n",
    "a√±os = sorted(info_archivos.keys())\n",
    "presencia = {}\n",
    "\n",
    "for var in sorted(todas_variables):\n",
    "    presencia[var] = []\n",
    "    for a√±o in a√±os:\n",
    "        if var in info_archivos[a√±o]['columnas']:\n",
    "            presencia[var].append('‚úì')\n",
    "        else:\n",
    "            presencia[var].append('-')\n",
    "\n",
    "# Mostrar como DataFrame\n",
    "df_presencia = pd.DataFrame(presencia, index=a√±os).T\n",
    "df_presencia.columns = [str(a) for a in a√±os]\n",
    "print(df_presencia.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72e96902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables presentes en TODOS los a√±os: 24\n",
      "--------------------------------------------------\n",
      "  ‚Ä¢ Asisrec\n",
      "  ‚Ä¢ A√±oreg\n",
      "  ‚Ä¢ Depnam\n",
      "  ‚Ä¢ Depnap\n",
      "  ‚Ä¢ Depocu\n",
      "  ‚Ä¢ Depreg\n",
      "  ‚Ä¢ Deprem\n",
      "  ‚Ä¢ Deprep\n",
      "  ‚Ä¢ Diaocu\n",
      "  ‚Ä¢ Edadm\n",
      "  ‚Ä¢ Edadp\n",
      "  ‚Ä¢ Escivm\n",
      "  ‚Ä¢ Escivp\n",
      "  ‚Ä¢ Libras\n",
      "  ‚Ä¢ Mesocu\n",
      "  ‚Ä¢ Mesreg\n",
      "  ‚Ä¢ Mupocu\n",
      "  ‚Ä¢ Onzas\n",
      "  ‚Ä¢ Sexo\n",
      "  ‚Ä¢ Sitioocu\n",
      "  ‚Ä¢ Tipar\n",
      "  ‚Ä¢ Tohinm\n",
      "  ‚Ä¢ Tohite\n",
      "  ‚Ä¢ Tohivi\n",
      "\n",
      "Variables presentes solo en ALGUNOS a√±os: 37\n",
      "--------------------------------------------------\n",
      "  ‚Ä¢ Areag: 2009, 2010, 2011\n",
      "  ‚Ä¢ A√±oocu: 2009, 2010, 2011, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Ciuomad: 2013\n",
      "  ‚Ä¢ Ciuopad: 2013\n",
      "  ‚Ä¢ Escolam: 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Escolap: 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Gretnm: 2009\n",
      "  ‚Ä¢ Gretnp: 2009, 2010, 2011, 2012\n",
      "  ‚Ä¢ Munpnap: 2014, 2015, 2016, 2017, 2018, 2019, 2020\n",
      "  ‚Ä¢ Mupnam: 2009, 2011, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Mupnap: 2009, 2011, 2012, 2013, 2021, 2022\n",
      "  ‚Ä¢ Mupreg: 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Muprem: 2009, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Muprep: 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Naciom: 2009, 2010, 2011, 2012, 2013\n",
      "  ‚Ä¢ Naciop: 2009, 2010, 2011, 2012, 2013\n",
      "  ‚Ä¢ Ocupam: 2009, 2010, 2011, 2012, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Ocupap: 2009, 2010, 2011, 2012, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Paisnacm: 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Paisnacp: 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Paisrem: 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ Paisrep: 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ PuebloPM: 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021\n",
      "  ‚Ä¢ PuebloPP: 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021\n",
      "  ‚Ä¢ Pueblopm: 2022\n",
      "  ‚Ä¢ Pueblopp: 2022\n",
      "  ‚Ä¢ TipoIns: 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022\n",
      "  ‚Ä¢ ViaPar: 2015, 2016, 2017, 2018, 2019, 2020, 2021\n",
      "  ‚Ä¢ Viapar: 2022\n",
      "  ‚Ä¢ ciuomad: 2014\n",
      "  ‚Ä¢ grupetma: 2010, 2011, 2012\n",
      "  ‚Ä¢ munnam: 2012\n",
      "  ‚Ä¢ mupnam: 2010\n",
      "  ‚Ä¢ mupnap: 2010\n",
      "  ‚Ä¢ mupreg: 2009, 2010\n",
      "  ‚Ä¢ muprem: 2010\n",
      "  ‚Ä¢ muprep: 2009, 2010\n"
     ]
    }
   ],
   "source": [
    "# Identificar variables comunes a todos los a√±os\n",
    "variables_comunes = todas_variables.copy()\n",
    "for a√±o, info in info_archivos.items():\n",
    "    variables_comunes = variables_comunes.intersection(set(info['columnas']))\n",
    "\n",
    "print(f\"Variables presentes en TODOS los a√±os: {len(variables_comunes)}\")\n",
    "print(\"-\" * 50)\n",
    "for var in sorted(variables_comunes):\n",
    "    print(f\"  ‚Ä¢ {var}\")\n",
    "\n",
    "# Variables que no est√°n en todos los a√±os\n",
    "variables_parciales = todas_variables - variables_comunes\n",
    "print(f\"\\nVariables presentes solo en ALGUNOS a√±os: {len(variables_parciales)}\")\n",
    "print(\"-\" * 50)\n",
    "for var in sorted(variables_parciales):\n",
    "    a√±os_presente = [str(a) for a in a√±os if var in info_archivos[a]['columnas']]\n",
    "    print(f\"  ‚Ä¢ {var}: {', '.join(a√±os_presente)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84f2e4",
   "metadata": {},
   "source": [
    "## 1.5 An√°lisis de tipos de datos\n",
    "\n",
    "Verificamos que las variables comunes tengan tipos de datos consistentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "056723ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIPOS DE DATOS POR VARIABLE Y A√ëO\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è Variables con tipos inconsistentes: 1\n",
      "  ‚Ä¢ Mupocu: {'str', 'float64'}\n",
      "\n",
      "Tipos de datos de variables comunes (referencia a√±o 2009):\n",
      "--------------------------------------------------\n",
      "  Asisrec              float64        \n",
      "  A√±oreg               float64        \n",
      "  Depnam               float64        \n",
      "  Depnap               float64        \n",
      "  Depocu               float64        \n",
      "  Depreg               float64        \n",
      "  Deprem               float64        \n",
      "  Deprep               float64        \n",
      "  Diaocu               float64        \n",
      "  Edadm                float64        \n",
      "  Edadp                float64        \n",
      "  Escivm               float64        \n",
      "  Escivp               float64        \n",
      "  Libras               float64        \n",
      "  Mesocu               float64        \n",
      "  Mesreg               float64        \n",
      "  Mupocu               str            \n",
      "  Onzas                float64        \n",
      "  Sexo                 float64        \n",
      "  Sitioocu             float64        \n",
      "  Tipar                float64        \n",
      "  Tohinm               float64        \n",
      "  Tohite               float64        \n",
      "  Tohivi               float64        \n"
     ]
    }
   ],
   "source": [
    "# Analizar tipos de datos de las variables comunes\n",
    "print(\"TIPOS DE DATOS POR VARIABLE Y A√ëO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "tipos_por_variable = {}\n",
    "for var in sorted(variables_comunes):\n",
    "    tipos = {}\n",
    "    for a√±o in a√±os:\n",
    "        if var in dataframes[a√±o].columns:\n",
    "            tipos[a√±o] = str(dataframes[a√±o][var].dtype)\n",
    "    tipos_por_variable[var] = tipos\n",
    "\n",
    "# Identificar inconsistencias\n",
    "inconsistencias = []\n",
    "for var, tipos in tipos_por_variable.items():\n",
    "    tipos_unicos = set(tipos.values())\n",
    "    if len(tipos_unicos) > 1:\n",
    "        inconsistencias.append((var, tipos_unicos))\n",
    "\n",
    "if inconsistencias:\n",
    "    print(f\"\\n‚ö†Ô∏è Variables con tipos inconsistentes: {len(inconsistencias)}\")\n",
    "    for var, tipos in inconsistencias:\n",
    "        print(f\"  ‚Ä¢ {var}: {tipos}\")\n",
    "else:\n",
    "    print(\"\\n‚úì Todas las variables comunes tienen tipos consistentes\")\n",
    "\n",
    "# Mostrar tipos de las variables comunes (tomando el primer a√±o como referencia)\n",
    "print(\"\\nTipos de datos de variables comunes (referencia a√±o 2009):\")\n",
    "print(\"-\" * 50)\n",
    "df_ref = dataframes[2009]\n",
    "for var in sorted(variables_comunes):\n",
    "    if var in df_ref.columns:\n",
    "        print(f\"  {var:<20} {str(df_ref[var].dtype):<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8100343",
   "metadata": {},
   "source": [
    "## 1.6 Uni√≥n de los datasets\n",
    "\n",
    "Procedemos a unir todos los archivos en un √∫nico DataFrame, utilizando solo las variables comunes para garantizar coherencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b4e6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A√±o 2009:    351,628 registros preparados\n",
      "A√±o 2010:    361,906 registros preparados\n",
      "A√±o 2011:    373,692 registros preparados\n",
      "A√±o 2012:    388,613 registros preparados\n",
      "A√±o 2013:    387,342 registros preparados\n",
      "A√±o 2014:    386,195 registros preparados\n",
      "A√±o 2015:    391,425 registros preparados\n",
      "A√±o 2016:    390,382 registros preparados\n",
      "A√±o 2017:    381,664 registros preparados\n",
      "A√±o 2018:    383,263 registros preparados\n",
      "A√±o 2019:    366,855 registros preparados\n",
      "A√±o 2020:    341,212 registros preparados\n",
      "A√±o 2021:    345,149 registros preparados\n",
      "A√±o 2022:    345,869 registros preparados\n",
      "\n",
      "Uniendo datasets...\n",
      "\n",
      "‚úì Dataset unificado creado exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Preparar lista de DataFrames para concatenar\n",
    "dfs_para_unir = []\n",
    "\n",
    "for a√±o in a√±os:\n",
    "    df_temp = dataframes[a√±o].copy()\n",
    "    \n",
    "    # Agregar columna de a√±o de origen si no existe A√±oocu\n",
    "    if 'A√±oocu' not in df_temp.columns:\n",
    "        df_temp['A√±oocu'] = a√±o\n",
    "    \n",
    "    # Seleccionar solo variables comunes + A√±oocu\n",
    "    cols_seleccionar = list(variables_comunes)\n",
    "    if 'A√±oocu' not in cols_seleccionar:\n",
    "        cols_seleccionar.append('A√±oocu')\n",
    "    \n",
    "    # Filtrar columnas existentes\n",
    "    cols_existentes = [c for c in cols_seleccionar if c in df_temp.columns]\n",
    "    df_temp = df_temp[cols_existentes]\n",
    "    \n",
    "    dfs_para_unir.append(df_temp)\n",
    "    print(f\"A√±o {a√±o}: {len(df_temp):>10,} registros preparados\")\n",
    "\n",
    "# Concatenar todos los DataFrames\n",
    "print(\"\\nUniendo datasets...\")\n",
    "df_completo = pd.concat(dfs_para_unir, ignore_index=True)\n",
    "print(f\"\\n‚úì Dataset unificado creado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356d8b1b",
   "metadata": {},
   "source": [
    "## 1.7 Verificaci√≥n del dataset unificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be1a7a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RESUMEN DEL DATASET UNIFICADO\n",
      "============================================================\n",
      "\n",
      "üìä Dimensiones:\n",
      "   ‚Ä¢ Total de registros (nacimientos): 5,195,195\n",
      "   ‚Ä¢ Total de variables: 25\n",
      "\n",
      "üìÖ Per√≠odo de datos:\n",
      "   ‚Ä¢ A√±o m√≠nimo: 2009\n",
      "   ‚Ä¢ A√±o m√°ximo: 2022\n",
      "   ‚Ä¢ Rango: 14 a√±os\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"RESUMEN DEL DATASET UNIFICADO\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dimensiones:\")\n",
    "print(f\"   ‚Ä¢ Total de registros (nacimientos): {len(df_completo):,}\")\n",
    "print(f\"   ‚Ä¢ Total de variables: {len(df_completo.columns)}\")\n",
    "\n",
    "# Verificar rango de a√±os\n",
    "if 'A√±oocu' in df_completo.columns:\n",
    "    df_completo['A√±oocu'] = pd.to_numeric(df_completo['A√±oocu'], errors='coerce')\n",
    "    # Normalizar a√±os (si est√°n en formato corto)\n",
    "    df_completo.loc[df_completo['A√±oocu'] < 100, 'A√±oocu'] = df_completo.loc[df_completo['A√±oocu'] < 100, 'A√±oocu'] + 2000\n",
    "    \n",
    "    a√±o_min = int(df_completo['A√±oocu'].min())\n",
    "    a√±o_max = int(df_completo['A√±oocu'].max())\n",
    "    print(f\"\\nüìÖ Per√≠odo de datos:\")\n",
    "    print(f\"   ‚Ä¢ A√±o m√≠nimo: {a√±o_min}\")\n",
    "    print(f\"   ‚Ä¢ A√±o m√°ximo: {a√±o_max}\")\n",
    "    print(f\"   ‚Ä¢ Rango: {a√±o_max - a√±o_min + 1} a√±os\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "160389c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Distribuci√≥n de nacimientos por a√±o:\n",
      "---------------------------------------------\n",
      "   2009:    351,628  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2010:    361,906  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2011:    373,692  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2012:    388,613  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2013:    387,342  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2014:    386,195  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2015:    391,425  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2016:    390,382  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2017:    381,664  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2018:    383,263  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2019:    366,855  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2020:    341,212  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2021:    345,149  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "   2022:    345,869  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "---------------------------------------------\n",
      "   TOTAL:  5,195,195\n"
     ]
    }
   ],
   "source": [
    "# Distribuci√≥n de registros por a√±o\n",
    "print(\"\\nüìà Distribuci√≥n de nacimientos por a√±o:\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "registros_por_a√±o = df_completo['A√±oocu'].value_counts().sort_index()\n",
    "\n",
    "for a√±o, registros in registros_por_a√±o.items():\n",
    "    barra = '‚ñà' * int(registros / 10000)\n",
    "    print(f\"   {int(a√±o)}: {registros:>10,}  {barra}\")\n",
    "\n",
    "print(\"-\" * 45)\n",
    "print(f\"   TOTAL: {registros_por_a√±o.sum():>10,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07494427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Verificaci√≥n de integridad:\n",
      "   ‚Ä¢ Suma de registros individuales: 5,195,195\n",
      "   ‚Ä¢ Total en dataset unificado: 5,195,195\n",
      "   ‚úì Los totales coinciden - Uni√≥n correcta\n"
     ]
    }
   ],
   "source": [
    "# Verificar consistencia: suma de archivos individuales vs dataset unificado\n",
    "suma_individual = sum(info['registros'] for info in info_archivos.values())\n",
    "total_unificado = len(df_completo)\n",
    "\n",
    "print(\"\\nüîç Verificaci√≥n de integridad:\")\n",
    "print(f\"   ‚Ä¢ Suma de registros individuales: {suma_individual:,}\")\n",
    "print(f\"   ‚Ä¢ Total en dataset unificado: {total_unificado:,}\")\n",
    "\n",
    "if suma_individual == total_unificado:\n",
    "    print(\"   ‚úì Los totales coinciden - Uni√≥n correcta\")\n",
    "else:\n",
    "    diferencia = abs(suma_individual - total_unificado)\n",
    "    print(f\"   ‚ö†Ô∏è Diferencia de {diferencia:,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "019d78e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Vista previa del dataset (primeras 5 filas):\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diaocu</th>\n",
       "      <th>Depnap</th>\n",
       "      <th>Sexo</th>\n",
       "      <th>Depreg</th>\n",
       "      <th>Deprep</th>\n",
       "      <th>Tohivi</th>\n",
       "      <th>Depocu</th>\n",
       "      <th>Edadp</th>\n",
       "      <th>Deprem</th>\n",
       "      <th>Mesreg</th>\n",
       "      <th>Mupocu</th>\n",
       "      <th>Tohinm</th>\n",
       "      <th>Tipar</th>\n",
       "      <th>Mesocu</th>\n",
       "      <th>Escivp</th>\n",
       "      <th>Libras</th>\n",
       "      <th>Tohite</th>\n",
       "      <th>Onzas</th>\n",
       "      <th>A√±oreg</th>\n",
       "      <th>Asisrec</th>\n",
       "      <th>Depnam</th>\n",
       "      <th>Sitioocu</th>\n",
       "      <th>Escivm</th>\n",
       "      <th>Edadm</th>\n",
       "      <th>A√±oocu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diaocu  Depnap  Sexo  Depreg  Deprep  Tohivi  Depocu  Edadp  Deprem  \\\n",
       "0    28.0     1.0   1.0     1.0     1.0     2.0     1.0   30.0     1.0   \n",
       "1     2.0     1.0   1.0     1.0     1.0     1.0     1.0   23.0     1.0   \n",
       "2    30.0     1.0   2.0     1.0     1.0     3.0     1.0   32.0     1.0   \n",
       "3     7.0     1.0   2.0     1.0     1.0     2.0     1.0   30.0     1.0   \n",
       "4    10.0     1.0   1.0     1.0     1.0     2.0     1.0   33.0     1.0   \n",
       "\n",
       "   Mesreg Mupocu  Tohinm  Tipar  Mesocu  Escivp  Libras  Tohite  Onzas  \\\n",
       "0     8.0   0101     0.0    1.0     6.0     1.0     5.0     2.0    2.0   \n",
       "1     3.0   0101     0.0    1.0     4.0     2.0     5.0     1.0    6.0   \n",
       "2     2.0   0101     0.0    1.0     1.0     2.0     5.0     3.0   10.0   \n",
       "3     1.0   0101     0.0    1.0     9.0     1.0     6.0     2.0    0.0   \n",
       "4     7.0   0101     0.0    1.0     7.0     1.0     6.0     2.0   10.0   \n",
       "\n",
       "   A√±oreg  Asisrec  Depnam  Sitioocu  Escivm  Edadm  A√±oocu  \n",
       "0     9.0      1.0     1.0       4.0     2.0   28.0  2009.0  \n",
       "1    10.0      1.0     1.0       4.0     2.0   18.0  2009.0  \n",
       "2     9.0      1.0     1.0       4.0     2.0   40.0  2009.0  \n",
       "3    10.0      1.0     1.0       4.0     1.0   28.0  2009.0  \n",
       "4     9.0      1.0     1.0       4.0     1.0   34.0  2009.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vista previa del dataset\n",
    "print(\"\\nüìã Vista previa del dataset (primeras 5 filas):\")\n",
    "print(\"=\" * 80)\n",
    "df_completo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "888410d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Informaci√≥n del dataset:\n",
      "================================================================================\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 5195195 entries, 0 to 5195194\n",
      "Data columns (total 25 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   Diaocu    float64\n",
      " 1   Depnap    float64\n",
      " 2   Sexo      float64\n",
      " 3   Depreg    float64\n",
      " 4   Deprep    float64\n",
      " 5   Tohivi    float64\n",
      " 6   Depocu    float64\n",
      " 7   Edadp     float64\n",
      " 8   Deprem    float64\n",
      " 9   Mesreg    float64\n",
      " 10  Mupocu    object \n",
      " 11  Tohinm    float64\n",
      " 12  Tipar     float64\n",
      " 13  Mesocu    float64\n",
      " 14  Escivp    float64\n",
      " 15  Libras    float64\n",
      " 16  Tohite    float64\n",
      " 17  Onzas     float64\n",
      " 18  A√±oreg    float64\n",
      " 19  Asisrec   float64\n",
      " 20  Depnam    float64\n",
      " 21  Sitioocu  float64\n",
      " 22  Escivm    float64\n",
      " 23  Edadm     float64\n",
      " 24  A√±oocu    float64\n",
      "dtypes: float64(24), object(1)\n",
      "memory usage: 990.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Informaci√≥n general del dataset\n",
    "print(\"\\nüìä Informaci√≥n del dataset:\")\n",
    "print(\"=\" * 80)\n",
    "df_completo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f78ffbf",
   "metadata": {},
   "source": [
    "## 1.8 Guardar dataset unificado\n",
    "\n",
    "Guardamos el dataset procesado para su uso en an√°lisis posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f58cb775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dataset guardado en: ..\\data\\processed\\nacimientos_2009_2022.csv\n",
      "  Tama√±o del archivo: 569.82 MB\n",
      "  Total de registros: 5,195,195\n",
      "  Total de variables: 25\n"
     ]
    }
   ],
   "source": [
    "# Crear carpeta de datos procesados si no existe\n",
    "PROCESSED_PATH = Path('../data/processed')\n",
    "PROCESSED_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Guardar en formato CSV \n",
    "output_csv = PROCESSED_PATH / 'nacimientos_2009_2022.csv'\n",
    "df_completo.to_csv(output_csv, index=False)\n",
    "print(f\"‚úì Dataset guardado en: {output_csv}\")\n",
    "print(f\"  Tama√±o del archivo: {output_csv.stat().st_size / (1024**2):.2f} MB\")\n",
    "print(f\"  Total de registros: {len(df_completo):,}\")\n",
    "print(f\"  Total de variables: {len(df_completo.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a0cdc0",
   "metadata": {},
   "source": [
    "## 1.9 Resumen de la etapa de carga y uni√≥n\n",
    "\n",
    "### Documentaci√≥n del proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2894efa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë             RESUMEN: CARGA Y UNI√ìN DE DATOS              ‚ïë\n",
      "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
      "‚ïë                                                          ‚ïë\n",
      "‚ïë  üìÅ Archivos procesados: 14                             ‚ïë\n",
      "‚ïë  üìÖ Per√≠odo: 2009 - 2022 (14 a√±os)                     ‚ïë\n",
      "‚ïë  üìä Total de registros: 5,195,195                       ‚ïë\n",
      "‚ïë  üìã Variables comunes: 24                               ‚ïë\n",
      "‚ïë                                                          ‚ïë\n",
      "‚ïë  ‚úì Datos verificados y unificados correctamente         ‚ïë\n",
      "‚ïë                                                          ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"‚ïî\" + \"‚ïê\" * 58 + \"‚ïó\")\n",
    "print(\"‚ïë\" + \" RESUMEN: CARGA Y UNI√ìN DE DATOS \".center(58) + \"‚ïë\")\n",
    "print(\"‚ï†\" + \"‚ïê\" * 58 + \"‚ï£\")\n",
    "print(\"‚ïë\" + \" \" * 58 + \"‚ïë\")\n",
    "print(f\"‚ïë  üìÅ Archivos procesados: {len(archivos_sav):<30} ‚ïë\")\n",
    "print(f\"‚ïë  üìÖ Per√≠odo: 2009 - 2022 ({a√±o_max - a√±o_min + 1} a√±os){' ' * 21}‚ïë\")\n",
    "print(f\"‚ïë  üìä Total de registros: {len(df_completo):,}{' ' * (32 - len(f'{len(df_completo):,}'))}‚ïë\")\n",
    "print(f\"‚ïë  üìã Variables comunes: {len(variables_comunes):<32} ‚ïë\")\n",
    "print(\"‚ïë\" + \" \" * 58 + \"‚ïë\")\n",
    "print(\"‚ïë  ‚úì Datos verificados y unificados correctamente\" + \" \" * 9 + \"‚ïë\")\n",
    "print(\"‚ïë\" + \" \" * 58 + \"‚ïë\")\n",
    "print(\"‚ïö\" + \"‚ïê\" * 58 + \"‚ïù\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad77bb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Crear diccionario de metadatos para documentaci√≥n\u001b[39;00m\n\u001b[32m      2\u001b[39m metadatos_proceso = {\n\u001b[32m      3\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfecha_procesamiento\u001b[39m\u001b[33m'\u001b[39m: pd.Timestamp.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m%\u001b[39m\u001b[33mH:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM:\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      4\u001b[39m     \u001b[33m'\u001b[39m\u001b[33marchivos_fuente\u001b[39m\u001b[33m'\u001b[39m: archivos_sav,\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtotal_archivos\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(archivos_sav),\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mperiodo\u001b[39m\u001b[33m'\u001b[39m: {\u001b[33m'\u001b[39m\u001b[33minicio\u001b[39m\u001b[33m'\u001b[39m: a√±o_min, \u001b[33m'\u001b[39m\u001b[33mfin\u001b[39m\u001b[33m'\u001b[39m: a√±o_max},\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtotal_registros\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mlen\u001b[39m(df_completo),\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mvariables_comunes\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(variables_comunes)),\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mvariables_parciales\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mlist\u001b[39m(variables_parciales)),\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mregistros_por_a√±o\u001b[39m\u001b[33m'\u001b[39m: registros_por_a√±o.to_dict(),\n\u001b[32m     11\u001b[39m     \u001b[33m'\u001b[39m\u001b[33marchivos_generados\u001b[39m\u001b[33m'\u001b[39m: [\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         \u001b[38;5;28mstr\u001b[39m(\u001b[43moutput_file\u001b[49m),\n\u001b[32m     13\u001b[39m         \u001b[38;5;28mstr\u001b[39m(output_csv)\n\u001b[32m     14\u001b[39m     ]\n\u001b[32m     15\u001b[39m }\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Guardar metadatos\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'output_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Crear diccionario de metadatos para documentaci√≥n\n",
    "metadatos_proceso = {\n",
    "    'fecha_procesamiento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'archivos_fuente': archivos_sav,\n",
    "    'total_archivos': len(archivos_sav),\n",
    "    'periodo': {'inicio': a√±o_min, 'fin': a√±o_max},\n",
    "    'total_registros': len(df_completo),\n",
    "    'variables_comunes': sorted(list(variables_comunes)),\n",
    "    'variables_parciales': sorted(list(variables_parciales)),\n",
    "    'registros_por_a√±o': registros_por_a√±o.to_dict(),\n",
    "    'archivos_generados': [\n",
    "        str(output_csv)\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Guardar metadatos\n",
    "import json\n",
    "with open(PROCESSED_PATH / 'metadatos_carga.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadatos_proceso, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(\"‚úì Metadatos del proceso guardados en: metadatos_carga.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d18704",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notas para la secci√≥n \"Descripci√≥n de los datos\"\n",
    "\n",
    "Este notebook documenta:\n",
    "\n",
    "1. **Fuente de datos:** 14 archivos SPSS (.sav) del INE de Guatemala\n",
    "2. **Per√≠odo cubierto:** 2009 a 2022\n",
    "3. **Unidad de an√°lisis:** Cada registro representa un nacimiento individual\n",
    "4. **Variables disponibles:** Se identificaron las variables comunes a todos los a√±os\n",
    "5. **Proceso de uni√≥n:** Concatenaci√≥n vertical de todos los archivos\n",
    "6. **Verificaci√≥n:** Se valid√≥ la integridad de los datos comparando totales\n",
    "\n",
    "El dataset resultante est√° listo para las siguientes etapas de an√°lisis exploratorio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
